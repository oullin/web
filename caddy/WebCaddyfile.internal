:80 {
    @relay_get {
        path /relay/*
        method GET
    }
    handle @relay_get { respond 405 }

    # Strip /relay and forward to API mTLS gateway
    handle_path /relay/* {
        rewrite * /api{path}
        reverse_proxy https://oullin_proxy_prod:8443 {
            header_up Host oullin_proxy_prod
            transport http {
                tls
                tls_server_name oullin_proxy_prod
                tls_client_auth /etc/caddy/mtls/client.pem /etc/caddy/mtls/client.key
                tls_trust_pool file /etc/caddy/mtls/ca.pem
            }
        }
    }

    # --- Normalise trailing slashes ("/about/" -> "/about")
    @has_trailing path_regexp trailing ^/(.+)/$
    @has_trailing_with_query {
      path_regexp trailing ^/(.+)/$
      expression {query} != ""
    }
    redir @has_trailing_with_query /{re.trailing.1}?{query} 308
    redir @has_trailing /{re.trailing.1} 308
    # --- end

    # Block direct access to the SEO folder (serve only via internal rewrites)
    handle /seo { respond 404 }
    handle_path /seo/* { respond 404 }

    # --- Serve static assets WITHOUT SPA fallback (prevents HTML at image URLs)
    handle_path /assets/* {
        root * /usr/share/caddy
        encode zstd gzip
        header Cache-Control "public, max-age=31536000, immutable"
        file_server
    }
    handle_path /images/* {
        root * /usr/share/caddy
        encode zstd gzip
        header Cache-Control "public, max-age=31536000, immutable"
        file_server
    }
    # --- end static assets

    # Optional: force SEO view for quick manual checks: /about?__seo=1
    @force_seo expression `{query}.matches("(^|&)(__seo=1)($|&)")`
    handle @force_seo {
        root * /usr/share/caddy
        try_files /seo{path}.seo.html /seo/index.seo.html {path} {path}/index.html /index.html
        encode zstd gzip
        header X-Share-Handler "bots-forced"
        header X-Share-Path "{path}"
        header Cache-Control "no-store, private"
        header Vary "User-Agent"
        file_server
    }

    # Bot/social previews → serve static share pages under /seo/*.seo.html
    @sharebots header_regexp ua User-Agent "(?i)(googlebot|bingbot|duckduckbot|yandex(bot|images)|baiduspider|facebookexternalhit|meta-externalagent|twitterbot|linkedinbot|slackbot|telegrambot|discordbot|pinterest|whatsapp|skypeuripreview|bitlybot|vkshare|quora link preview|embedly|outbrain|nuzzel|ios link preview|snapchat|applebot|google-inspectiontool|googleother)"
    handle @sharebots {
        root * /usr/share/caddy

        # Try SEO flat files first, then SPA files
        try_files /seo{path}.seo.html /seo/index.seo.html {path} {path}/index.html /index.html

        encode zstd gzip

        # Positive debug signals
        header X-Share-Handler "bots"
        header X-Share-Path "{path}"

        # Make bot responses uncacheable at shared caches
        @share_html {
            not path /assets/*
            not path /images/*
            not path /relay/*
            not path /seo/*
            not path /favicon.ico
            not path /robots.txt
        }
        header @share_html Cache-Control "no-store, private"
        header @share_html Vary "User-Agent"

        # Explicit caching for common top-level files
        @favicon path /favicon.ico
        header @favicon Cache-Control "public, max-age=31536000, immutable"

        @robots path /robots.txt
        header @robots Cache-Control "public, max-age=300"

        # Security headers for bot responses too
        header {
            Referrer-Policy "strict-origin-when-cross-origin"
            X-Content-Type-Options "nosniff"
            X-Frame-Options "SAMEORIGIN"
        }

        file_server
    }

    # --- Everyone else → SPA (humans) ---
    handle {
        root * /usr/share/caddy
        try_files {path} {path}/index.html /index.html
        encode zstd gzip

        header X-Share-Handler "humans"

        # Explicit caching for top-level files
        @favicon path /favicon.ico
        header @favicon Cache-Control "public, max-age=31536000, immutable"

        @robots path /robots.txt
        header @robots Cache-Control "public, max-age=300"

        @html {
            not path /assets/*
            not path /images/*
            not path /relay/*
            not path /seo/*
        }
        header @html Cache-Control "public, max-age=300, stale-while-revalidate=60"
        header @html Vary "User-Agent"

        header {
            Referrer-Policy "strict-origin-when-cross-origin"
            X-Content-Type-Options "nosniff"
            X-Frame-Options "SAMEORIGIN"
        }

        file_server
    }

    log {
        output stdout
        format json
    }
}
